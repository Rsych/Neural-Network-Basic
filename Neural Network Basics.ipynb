{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb6b217",
   "metadata": {},
   "source": [
    "# Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa0d0fc",
   "metadata": {},
   "source": [
    "## Perceptron Algorithm\n",
    "\n",
    "\n",
    "The perceptron algorithm was invented in 1958 at the Cornell Aeronautical Laboratory by Frank Rosenblatt. Perceptron mimics neuron, inputs data from other neurons and outputs to other neurons. \n",
    "\n",
    "Perceptron has its own weights `w1, w2, ...`, with input `x1, x2, ...`, total sum of inputs `x1w1 + x2w2 + ...` is lower than threshold $\\theta$ outputs 0 vice versa, it is called activate.\n",
    "\n",
    "Without changing structure, by changing weights and threshold we can build AND, NAND and OR gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad38498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def AND(x1, x2):\n",
    "    w1 = 0.5\n",
    "    w2 = 0.5\n",
    "    theta = 0.7\n",
    "    if w1 * x1 + w2 * x2 > theta:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "print(AND(0,0))\n",
    "print(AND(0,1))\n",
    "print(AND(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88db391",
   "metadata": {},
   "source": [
    "Using multiple perceptrons we can also build XOR gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4df5f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def NAND(x1, x2):\n",
    "    w1 = -0.5\n",
    "    w2 = -0.5\n",
    "    theta = -0.7\n",
    "    if w1 * x1 + w2 * x2 > theta:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def OR(x1, x2):\n",
    "    w1 = 0.5\n",
    "    w2 = 0.5\n",
    "    theta = 0.2\n",
    "    if w1 * x1 + w2 * x2 > theta:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def XOR(x1, x2):\n",
    "    return AND(NAND(x1, x2), OR(x1, x2))\n",
    "\n",
    "print(XOR(0,0))\n",
    "print(XOR(0,1))\n",
    "print(XOR(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a216dfe",
   "metadata": {},
   "source": [
    "## Activation Function\n",
    "\n",
    "Activation function outputs specific values when sum of inputs exceeds threshold. Step function, Sigmoid function, Tanh function and ReLu (Rectified linear unit) function are most commonly used activation functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80714fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
